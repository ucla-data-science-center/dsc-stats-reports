---
title: "Infrastructure Statistics"
format:
  html:
    toc: true
    code-fold: true
jupyter: python3
---

```{python}
#| echo: false
#| message: false
#| warning: false

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
from IPython.display import display, Markdown

# Add scripts directory to path so we can import our cleaning logic
sys.path.append(os.path.abspath('src/etl'))
import aws_processing
from datetime import datetime
from dateutil.relativedelta import relativedelta

# Configuration
DATA_DIR = "data/raw/infrastructure/AWS_Costs/"
DATAVERSE_DIR = "data/raw/infrastructure/"
charge_dir = os.path.join(DATA_DIR, 'aws-charges')

# 1. Load Historical Data (CSV)
df_history = aws_processing.process_aws_data(DATA_DIR)

# 2. Fetch Live Data (Last 12 Months)
# AWS allows retrieval within the last 14 months. We use 12 for safety.
end_date = datetime.now().strftime('%Y-%m-01')
start_date = (datetime.now() - relativedelta(months=12)).strftime('%Y-%m-01')

try:
    df_live = aws_processing.fetch_aws_costs(start_date, end_date)
    if df_live.empty:
        print("Warning: Live AWS data fetch returned empty.")
        df_aws = df_history
    else:
        # 3. Merge: Filter history to exclude the period covered by live data
        # Ensure we use live data for the overlap period as it's more accurate/dynamic
        live_start = pd.to_datetime(start_date)
        df_history_filtered = df_history[df_history['date'] < live_start]
        
        df_aws = pd.concat([df_history_filtered, df_live], ignore_index=True)
        
except Exception as e:
    print(f"Error fetching live AWS data: {e}. Falling back to CSV only.")
    df_aws = df_history

df_ledger = aws_processing.extract_ledger_costs(charge_dir)
df_s3 = aws_processing.fetch_s3_storage_stats()
df_potree_growth = aws_processing.fetch_s3_historical_growth('potree-test2', days=180)

def print_markdown_table(headers, rows):
    table_str = "\n| " + " | ".join(headers) + " |\n"
    table_str += "| " + " | ".join(["---"] * len(headers)) + " |\n"
    for row in rows:
        row_str = [str(cell) for cell in row]
        table_str += "| " + " | ".join(row_str) + " |\n"
    display(Markdown(table_str))
```

# AWS Cloud Costs

## Monthly Departmental Charges (Ledger)
```{python}
#| echo: false
#| results: asis
if not df_ledger.empty:
    table_data = [[r['month'], f"${r['ledger_cost']:,.2f}"] for _, r in df_ledger.sort_values('month', ascending=False).iterrows()]
    print_markdown_table(["Month", "Actual Cost Charged"], table_data)
else:
    print("No ledger data found.")
```

## Monthly Trends
```{python}
#| echo: false
if not df_aws.empty:
    df_aws['month_label'] = df_aws['date'].dt.strftime('%Y-%m')
    monthly = df_aws.groupby(['month_label', 'application'])['cost'].sum().unstack(fill_value=0)
    monthly.plot(kind='bar', stacked=True, colormap='tab10', figsize=(10, 5))
    plt.legend(title='Application', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.title('Monthly AWS Costs')
    plt.tight_layout()
    plt.show()
```

# UCLA Dataverse Usage

## Repository Growth (Cumulative)
```{python}
#| echo: false
try:
    df_dv = pd.read_csv(os.path.join(DATAVERSE_DIR, 'datasets_files_published_monthly.csv'))
    df_dv['date'] = pd.to_datetime(df_dv['date'], format='%Y-%m')
    
    plt.figure(figsize=(10, 5))
    plt.plot(df_dv['date'], df_dv['datasets_published'], label='Datasets', color='#2774AE', linewidth=2)
    plt.plot(df_dv['date'], df_dv['files_published'], label='Files', color='#FFD100', linewidth=2)
    plt.yscale('log')
    plt.title('Dataverse Growth (Log Scale)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()
except Exception as e:
    print(f"Dataverse data missing: {e}")
```

## Monthly Activity
```{python}
#| echo: false
try:
    df_dv['month_new_datasets'] = df_dv['datasets_published'].diff().fillna(0)
    df_dv['month_new_files'] = df_dv['files_published'].diff().fillna(0)
    
    # Filter to last 2 years for activity
    df_recent = df_dv.tail(24)
    
    fig, ax1 = plt.subplots(figsize=(10, 5))
    
    ax1.bar(df_recent['date'], df_recent['month_new_datasets'], color='#2774AE', alpha=0.7, width=20, label='New Datasets')
    ax1.set_ylabel('New Datasets', color='#2774AE')
    
    ax2 = ax1.twinx()
    ax2.plot(df_recent['date'], df_recent['month_new_files'], color='#8B6F00', marker='o', label='New Files')
    ax2.set_ylabel('New Files', color='#8B6F00')
    
    plt.title('Dataverse Monthly Activity (Last 24 Months)')
    fig.tight_layout()
    plt.show()
except Exception as e:
    print(f"Error calculating monthly activity: {e}")
```

# S3 Bucket Storage

## Current Bucket Sizes
```{python}
#| echo: false
#| results: asis
if not df_s3.empty:
    table_data = [[r['bucket'], f"{r['size_gb']:.2f} GB", r['last_updated'].strftime('%Y-%m-%d')] for _, r in df_s3.sort_values('size_gb', ascending=False).iterrows()]
    print_markdown_table(["Bucket Name", "Size (GB)", "Last Updated"], table_data)
else:
    print("S3 storage data currently unavailable (Live AWS connection required).")
```

## Potree Storage Growth (180 Days)
```{python}
#| echo: false
if not df_potree_growth.empty:
    plt.figure(figsize=(10, 5))
    plt.plot(df_potree_growth['date'], df_potree_growth['size_gb'], color='#1f77b4', linewidth=2)
    plt.fill_between(df_potree_growth['date'], df_potree_growth['size_gb'], alpha=0.2)
    plt.title('Potree Storage Growth (GB)')
    plt.ylabel('Size (GB)')
    plt.grid(True, alpha=0.3)
    plt.show()
else:
    print("Growth data for Potree unavailable.")
```